import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

(train_X, train_Y), (test_X, test_Y) = tf.keras.datasets.mnist.load_data()
print(train_X.shape, train_Y.shape)

#데이터 정규화
train_X = train_X/255.0
test_X = test_X/255.0

#MNIST 데이터세트 확인
import matplotlib.pyplot as plt
plt.imshow(train_X[0].reshape(28,28), cmap = 'gray')
plt.colorbar()
plt.show()

print(train_Y[0])

print(train_X.shape)
train_X = train_X.reshape(-1,28 * 28)
test_X = test_X.reshape(-1,28 * 28)
print(train_X.shape, train_Y.shape)

#Dense 오토인코더 모델 정의
model = tf.keras.Sequential([
    tf.keras.layers.Dense(784, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(4, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(784, activation='sigmoid')
])

model.compile(optimizer =tf.optimizers.Adam(), loss= 'mse')
model.summary()

model.fit(train_X, train_X, epochs=10, batch_size= 256)

#테스트 데이터로 Dense 오토인코더의 이미지 
import random

plt.figure(figsize= (4,8))
for c in range(4):
  plt.subplot(4, 2, c*2+1)
  rand_index = random.randint(0, test_X.shape[0])
  plt.imshow(test_X[rand_index].reshape(28,28), cmap = 'gray')
  plt.axis('off')

  plt.subplot(4, 2, c*2+2)
  img = model.predict(np.expand_dims(test_X[rand_index], axis=0))
  plt.imshow(img.reshape(28, 28), cmap = 'gray')
  plt.axis('off')

plt.show()

model.evaluate(test_X, test_X)

#Convolution 오토인코더 모델 정의
train_X = train_X.reshape(-1, 28,28,1)
test_X = test_X.reshape(-1, 28,28,1)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=32, kernel_size=2, strides=(2,2), activation='relu',input_shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(filters=64, kernel_size=2, strides=(2,2), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(7*7*64, activation='relu'),
    tf.keras.layers.Reshape(target_shape = (7,7,64)),
    tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=2, strides=(2,2),padding='same', activation='relu'),
    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=2, strides=(2,2),padding='same', activation='sigmoid')
])

model.compile(optimizer=tf.optimizers.Adam(), loss = 'mse')
model.summary()
model.fit(train_X, train_X, epochs=20, batch_size=256)

#Convolution 오토인코더의 이미지 재생성
import random

plt.figure(figsize= (4,8))
for c in range(4):
  plt.subplot(4, 2, c*2+1)
  rand_index = random.randint(0, test_X.shape[0])
  plt.imshow(test_X[rand_index].reshape(28,28), cmap = 'gray')
  plt.axis('off')

  plt.subplot(4, 2, c*2+2)
  img = model.predict(np.expand_dims(test_X[rand_index], axis=0))
  plt.imshow(img.reshape(28, 28), cmap = 'gray')
  plt.axis('off')

plt.show()

model.evaluate(test_X, test_X)

#convolution한 데이터가 들어있는 latent_vector를 설정
latent_vector_model = tf.keras.Model(inputs = model.input, outputs=model.layers[3].output)
latent_vector = latent_vector_model.predict(train_X)

%time
from sklearn.cluster import KMeans

#k Means Clustering을 사용해 데이터를 분류
kmeans = KMeans(n_clusters = 10, n_init = 10, random_state = 42)
kmeans.fit(latent_vector)

#K Means Clustering을 사용해 분류한 이미지 확인
plt.figure(figsize = (12, 12))

for i in range(10):
    images = train_X[kmeans.labels_ == i]
    for c in range(10):
        plt.subplot(10, 10, i*10+c+1)
        plt.imshow(images[c].reshape(28,28), cmap = 'gray')
        plt.axis('off')
        
plt.show()

#TSEN으로 latent_vector 확인하기
%%time
from sklearn.manifold import TSNE

tsne = TSNE(n_components = 2, learning_rate = 100, perplexity = 15) TSEN으로 결과 실행
tsne_vector = tsne.fit_transform(latent_vector[:5000])#latent_vector를 앞에서 부터 5000개를 짜름

#matplotlib라이브러리를 활용해서 TSEN결과를 확인
cmap = plt.get_cmap('rainbow', 10)
fig = plt.scatter(tsne_vector[:,0], tsne_vector[:,1], marker = '.', c=train_Y[:5000], cmap = cmap)
cb = plt.colorbar(fig, ticks=range(10))
n_clusters = 10
tick_locs = (np.arange(n_clusters)+ 0.5)*(n_clusters-1)/n_clusters
cb.set_ticks(tick_locs)
cb.set_ticklabels(range(10))

#최근접 이웃숫자를 바꿔가면서 분류가 어떻게 되는지 확인
%%time

perplexities = [5, 10, 15, 25, 50, 100]
plt.figure(figsize = (8,12))

for c in range(6):
    tsne = TSNE(n_components = 2, learning_rate = 100, perplexity = perplexities[c])
    tsne_vector = tsne.fit_transform(latent_vector[:5000])
    
    plt.subplot(3, 2, c+1)
    plt.scatter(tsne_vector[:,0], tsne_vector[:,1], marker='.', c=train_Y[:5000], cmap = 'rainbow')
    plt.title('perplexity:{0}'.format(perplexities[c]))

plt.show()
