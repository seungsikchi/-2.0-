import pandas as pd
import numpy as np

#와인 데이터 세트 
red = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')
white = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')

#와인 데이터 세트 합치기
red['type'] = 0
white['type'] = 1
print(red.head(2))
print(white.head(2))

wine = pd.concat([red, white])
print(wine.describe())

#레드 와인과 화이트 와인에 대한 type 히스토그램
import matplotlib.pyplot as plt
plt.hist(wine['type'])
plt.xticks([0,1])
plt.show()

#데이터 요약 정보 확인
print(wine['type'].value_counts())

#데이터 정규화
wine_norm = (wine - wine.min()) / (wine.max() - wine.min())
print(wine_norm.head())
print(wine_norm.describe())

#데이터를 섞은 후 넘파이array로 변환
wine_shuffle = wine_norm.sample(frac = 1)
print(wine_shuffle.head())
wine_np = wine_shuffle.to_numpy()
print(wine_np[:5])

#훈련데이터와 테스트 데이터로 분리
import tensorflow as tf
train_idx = int(len(wine_np)*0.8)
train_X, train_Y = wine_np[:train_idx, :-1], wine_np[:train_idx, -1]
test_X, test_Y = wine_np[train_idx:, :-1], wine_np[train_idx:,-1]
print(train_X[0])
print(train_Y[0])
print(test_X[0])
print(test_Y[0])
train_Y = tf.keras.utils.to_categorical(train_Y, num_classes = 2)
test_Y = tf.keras.utils.to_categorical(test_Y, num_classes = 2)
print(train_Y[0])
print(test_Y[0])     

#와인 데이터세트 분류 모델 생성
model = tf.keras.Sequential([
  tf.keras.layers.Dense(units = 48, activation = 'relu', input_shape = (12,)),
  tf.keras.layers.Dense(units = 24, activation = 'relu'),
  tf.keras.layers.Dense(units = 12, activation = 'relu'),
  tf.keras.layers.Dense(units = 2, activation = 'softmax')
])

model.compile(optimizer = tf.keras.optimizers.Adam(lr = 0.07), loss = 'categorical_crossentropy',metrics = ['accuracy'])

model.summary()

history = model.fit(train_X, train_Y, epochs = 25, batch_size = 32, validation_split = 0.25) #와인 데이터세트에 대한 분류 모델 학습

#분류 모델의 학습 결과 시각화
plt.figure(figsize = (12,4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], 'b-', label = 'loss')
plt.plot(history.history['val_loss'], 'r--', label = 'val_loss')

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], 'g-', label = 'accuracy')
plt.plot(history.history['val_accuracy'], 'k--', label = 'val_accuracy')

model.evaluate(test_X, test_Y)
