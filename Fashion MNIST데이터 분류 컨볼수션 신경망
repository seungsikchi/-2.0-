import tensorflow as tf

fashion_mnist = tf.keras.datasets.fashion_mnist 
(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()

train_X = train_X / 255.0
test_X = test_X / 255.0

#reshape 이전
print(train_X.shape , test_X.shape)

train_X = train_X.reshape(-1, 28, 28, 1)
test_X = test_X.reshape(-1, 28, 28, 1)

#reshape 이후
print(train_X.shape, test_X.shape)

#Fashion MNIST 안에 있는 데이터 확인
import matplotlib.pyplot as plt

plt.figure(figsize = (10, 10))
for c in range(16):
  plt.subplot(4, 4, c+1)
  plt.imshow(train_X[c].reshape(28,28), cmap = 'gray')

plt.show()

#훈련 데이터의 첫번째 ~ 16번째 까지의 라벨을 프린트
print(train_Y[:16])

#Fashion MNIST모델에 풀링레이어, 드롭아웃 추가
model = tf.keras.Sequential([
  tf.keras.layers.Conv2D(input_shape = (28,28,1),kernel_size = (3,3), filters = 32),
  tf.keras.layers.MaxPool2D(strides = (2,2)),
  tf.keras.layers.Conv2D(kernel_size = (3,3), filters = 64),
  tf.keras.layers.MaxPool2D(strides = (2,2)),
  tf.keras.layers.Conv2D(kernel_size = (3,3), filters = 128),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(units = 128, activation= 'relu'),
  tf.keras.layers.Dropout(rate = 0.5),
  tf.keras.layers.Dense(units = 10, activation= 'softmax'),
])

model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

model.summary()

#학습 후 Loss값이랑 Accuracy값 확인
import matplotlib.pyplot as plt

plt.figure(figsize = (12,4))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], 'b-', label = 'loss')
plt.plot(history.history['val_loss'], 'r--', label = 'val_loss')
plt.xlabel('Epochs')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], 'g-', label = 'accuracy')
plt.plot(history.history['val_accuracy'], 'k--', label = 'val_accuracy')
plt.xlabel('Epochs')
plt.ylim(0.7, 1)
plt.legend()


model.evaluate(test_X, test_Y, verbose = 0)
