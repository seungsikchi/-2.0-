import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

#BSD500데이터 세트 불러오기
tf.keras.utils.get_file('/content/bsd_images.zip', 'http://bit.ly/35pHZIC', extract = True)

!unzip /content/bsd_images.zip

#이미지 주소설정하고 불러와 앞에서 10개까지만 뽑아내기
import pathlib
image_root = pathlib.Path('/content/images')

all_image_paths = list(image_root.glob('*/*'))
print(all_image_paths[:10])

#앞에서 뽑아낸 10개를 matplotlib를 사용해서 확인하기
import PIL.Image as Image
import matplotlib.pyplot as plt

plt.figure(figsize = (12,12))
for c in range(9):
  plt.subplot(3, 3, c+1)
  plt.imshow(plt.imread(all_image_paths[c]))
  plt.title(all_image_paths[c])
  plt.axis('off')

plt.show()

#원본 이미지에서 조각을 추출하고 입력, 출력 데이터를 반환하는 함수 정의
def get_hr_and_lr(image_path):
    img = tf.io.read_file(image_path) #이미지를 읽음
    img = tf.image.decode_jpeg(img, channels=3) #이미지를 decoding 함 차원수는 3차원 = R G B
    img = tf.image.convert_image_dtype(img, tf.float32) #타입을 실수형으로 설정

    hr = tf.image.random_crop(img, [50, 50, 3]) #고해상도 이미지를 hr이름으로 저장
    lr = tf.image.resize(hr, [25, 25])#resize하여서 1/2크기로 축소
    lr = tf.image.resize(lr, [50, 50])#원래 크기로 확대해서 저해상도 이미지인 lr을 생성
    return lr, hr

#train, valid Dataset정의
train_dataset = tf.data.Dataset.list_files(train_path)#dataset정의
train_dataset = train_dataset.map(get_hr_and_lr)#새로운 dataset정의하고 hr과 lr을 얻음
train_dataset = train_dataset.repeat()#데이터 계속 학습시키기을 위해 repeat()함수 호출
train_dataset = train_dataset.batch(16)#데이터의 batch_size를 16으로 설정

valid_dataset = tf.data.Dataset.list_files(valid_path)#dataset정의
valid_dataset = valid_dataset.map(get_hr_and_lr)#새로운 dataset정의하고 hr과 lr을 얻음
valid_dataset = valid_dataset.repeat()#데이터 계속 학습시키기을 위해 repeat()함수 호출
valid_dataset = valid_dataset.batch(1)#데이터의 batch_size를 1으로 설정

#REDNet 네트워크 정의(Funtion API)
def REDNet(num_layers):
    conv_layers = []
    deconv_layers = []
    residual_layers = []

    inputs = tf.keras.layers.Input(shape=(None, None, 3))
    conv_layers.append(tf.keras.layers.Conv2D(3, kernel_size=3, padding='same', activation='relu'))

    for i in range(num_layers-1):
        conv_layers.append(tf.keras.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'))
        deconv_layers.append(tf.keras.layers.Conv2DTranspose(64, kernel_size=3, padding='same', activation='relu'))

    deconv_layers.append(tf.keras.layers.Conv2DTranspose(3, kernel_size=3, padding='same'))

    # 인코더 시작
    x = conv_layers[0](inputs)

    for i in range(num_layers-1):
        x = conv_layers[i+1](x)
        if i % 2 == 0:
            residual_layers.append(x)

    # 디코더 시작
    for i in range(num_layers-1):
        if i % 2 == 1:
            x = tf.keras.layers.Add()([x, residual_layers.pop()])
            x = tf.keras.layers.Activation('relu')(x)
        x = deconv_layers[i](x) 

    x = deconv_layers[-1](x)
    
    model = tf.keras.Model(inputs=inputs, outputs=x)
    return model
    
def psnr_metric(y_true, y_pred): #결과를 쉽게 확인하기 위해 psnr_metric를 설정
    return tf.image.psnr(y_true, y_pred, max_val=1.0)

#모델을 학습
model = REDNet(15)
model.compile(optimizer=tf.optimizers.Adam(0.0001), loss='mse', metrics=[psnr_metric])
history = model.fit_generator(train_dataset, 
                              epochs=1000, 
                              steps_per_epoch=len(train_path)//16, 
                              validation_data=valid_dataset, 
                              validation_steps=len(valid_path), 
                              verbose=2)

#REDNet 네트워크 학습 결과 육안으로 확인하기
plt.plot(history.history['psnr_metric'], 'b-', label = 'psnr')
plt.plot(history.history['val_psnr_metric'], 'r--', label = 'val_psnr')

plt.xlabel('Epochs')
plt.legend()
plt.show()


#test 이미지에 대한 초 해상도
img = tf.io.read_file(test_path[0])
img = tf.image.decode_jpeg(img, channels=3)
hr = tf.image.convert_image_dtype(img, tf.float32)

lr = tf.image.resize(hr, [hr.shape[0]//2, hr.shape[1]//2])
lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])
predict_hr = model.predict(np.expand_dims(lr, axis=0))

print(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0))
print(tf.image.psnr(lr, hr, max_val=1.0))


#test 이미지에 대한 초해상도 결과 확인
plt.figure(figsize = (16,4))

plt.subplot(1, 3, 1)
plt.imshow(hr)
plt.title('original - hr')

plt.subplot(1, 3, 2)
plt.imshow(lr)
plt.title('lr')

plt.subplot(1, 3, 3)
plt.imshow(np.squeeze(predict_hr, axis=0))
plt.title('sr')

#같은 과정을  Set5 나비이미지로 테스트
#이미지 불러오기
image_path = tf.keras.utils.get_file('butterfly.png', 'http://bit.ly/2oAOxgH')
img = tf.io.read_file(image_path)
img = tf.image.decode_jpeg(img, channels=3)#이미지를 불러와 decoding 하는 과정 차원=3개 => R G B
hr = tf.image.convert_image_dtype(img, tf.float32)#불러온 이미지파일을 실수형으로 바꾸기 

lr = tf.image.resize(hr, [hr.shape[0]//2, hr.shape[1]//2]) #이미지를 2배 작은크기로 축소
lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])#이미지를 다시 확대
predict_hr = model.predict(np.expand_dims(lr, axis=0))결과 확인하기

print(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0))#마지막 hr의 PSNR점수 나타내기
print(tf.image.psnr(lr, hr, max_val=1.0))#lr과 hr의 PSNR점수 나타내기

#Decoding 결과를 눈으로 확인하기 위해서 이미지 출력
plt.figure(figsize=(16,6))
plt.subplot(1, 3, 1)
plt.imshow(hr)
plt.title('original - hr')

plt.subplot(1, 3, 2)
plt.imshow(lr)
plt.title('lr')

plt.subplot(1, 3, 3)
plt.imshow(np.squeeze(predict_hr, axis=0))
plt.title('sr')

import random
def get_hr_and_lr_flip_s4(image_path):
    img = tf.io.read_file(image_path)#이미지를 읽음
    img = tf.image.decode_jpeg(img, channels=3)#이미지를 decoding함 채널3개 = R G B
    img = tf.image.convert_image_dtype(img, tf.float32)#이미지 타입을 실수형으로 지정

    hr = tf.image.random_crop(img, [50, 50, 3])#이미지를 잘라냄 50,50에 컬러로 RGB 3차원으로
    lr = tf.image.resize(hr, [12, 12])#이미지를 4배 축소시킴
    lr = tf.image.resize(lr, [50, 50])#이미지르 다시 확대시킴
    
    if random.random() < 0.25:
        hr = tf.image.flip_left_right(hr)#0.25%확률로 이미지를 뒤집어서 데이터량을 늘림
        lr = tf.image.flip_left_right(lr)#0.25%확률로 이미지를 뒤집어서 데이터량을 늘림
    if random.random() < 0.25:
        hr = tf.image.flip_up_down(hr)#0.25%확률로 이미지를 뒤집어서 데이터량을 늘림
        lr = tf.image.flip_up_down(lr)#0.25%확률로 이미지를 뒤집어서 데이터량을 늘림
    
    return lr, hr

#REDNet 네트워크 학습
train_dataset = tf.data.Dataset.list_files(train_path)#데이터를 불러옴
train_dataset = train_dataset.map(get_hr_and_lr_flip_s4)#위에 했던거처럼 이미지를 반전시켜 데이터양을 늘림
train_dataset = train_dataset.repeat()#데이터를 계속 학습시키기위해 repeat()함수 사용
train_dataset = train_dataset.batch(16)#batch_size를 16으로 설정

valid_dataset = tf.data.Dataset.list_files(valid_path)#데이터를 불러옴
valid_dataset = valid_dataset.map(get_hr_and_lr_flip_s4))#위에 했던거처럼 이미지를 반전시켜 데이터양을 늘림
valid_dataset = valid_dataset.repeat()#데이터를 계속 학습시키기위해 repeat()함수 사용
valid_dataset = valid_dataset.batch(1)#batch_size를 1으로 설정

model = REDNet(15)
model.compile(optimizer=tf.optimizers.Adam(0.0001), loss='mse', metrics=[psnr_metric])
model.summary()

history = model.fit_generator(train_dataset, 
                              epochs=100, 
                              steps_per_epoch=len(train_path)//16, 
                              validation_data=valid_dataset, 
                              validation_steps=len(valid_path), 
                              verbose=2)


set5_image_root = pathlib.Path('/content/Set5')
set5_image_paths = list(set5_image_root.glob('*.*'))

sr_psnr = []
lr_psnr = []

for image_path in set5_image_paths:
    img = tf.io.read_file(str(image_path))
    img = tf.image.decode_jpeg(img, channels=3)
    hr = tf.image.convert_image_dtype(img, tf.float32)

    lr = tf.image.resize(hr, [hr.shape[0]//4, hr.shape[1]//4])
    lr = tf.image.resize(lr, [hr.shape[0], hr.shape[1]])
    predict_hr = model.predict(np.expand_dims(lr, axis=0))
    
    sr_psnr.append(tf.image.psnr(np.squeeze(predict_hr, axis=0), hr, max_val=1.0).numpy())
    lr_psnr.append(tf.image.psnr(lr, hr, max_val=1.0).numpy())
    
print('sr:', sr_psnr)
print('sr mean:', np.mean(sr_psnr))
print()
print('lr:', lr_psnr)
print('lr mean:', np.mean(lr_psnr))
