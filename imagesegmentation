import tensorflow_datasets as tfds
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

#데이터셋을 불러오는 명령어
dataset, info = tfds.load('oxford_iiit_pet:3.2.0', with_info = True)

#데이터셋 중에 사용할 image, segmentationmask 데이터 불러오기
train_data_len = info.splits['train'].num_examples
test_data_len = info.splits['test'].num_examples

#이미지 로드 함수
def load_image(datapoint):
  img = tf.image.resize(datapoint['image'], (128, 128))#이미지를 불러서 사이즈를 128,128로 설정
  mask = tf.image.resize(datapoint['segmentation_mask'], (128,128))#이미지 위에 segmentation할 마스크 생성 사이즈 128, 128

  img = tf.cast(img, tf.float32)#이미지를 실수형으로 변경
  img = img /255.0 #불러온 데이터를 결과가 좀더 잘 나오도록 정규화 시킴
  mask -= 1
  return img,mask

train_dataset = dataset['train'].map(load_image) #train_dataset불러오기
train_dataset = train_dataset.repeat()#데이터를 계속 학습시키기 위해 repeat()함수 사용
train_dataset = train_dataset.batch(16)#데이터의 batch_size를 16으로 설정

test_dataset = dataset['test'].map(load_image)#test_dataset불러오기
test_dataset = test_dataset.repeat()#데이터를 계속 학습시키기 위해 repeat()함수 사용
test_dataset = test_dataset.batch(1)#데이터의 batch_size를 1으로 설정

#image, segmentation mask 확인
for img, mask in train_dataset.take(1):
  plt.figure(figsize = (10,5))
  
  plt.subplot(1, 2, 1)
  plt.imshow(img[2])

  plt.subplot(1, 2, 2)
  plt.imshow(np.squeeze(mask[2], axis=2))
  plt.colorbar()
  
#REDNet 모델 생성하기(앞에서 사용한 REDNet과 동일)
def REDNet_segmentation(num_layers):
  conv_layers = []
  deconv_layers = []
  residual_layers = []

  inputs = tf.keras.layers.Input(shape=(None, None, 3))
  conv_layers.append(tf.keras.layers.Conv2D(3, kernel_size=3, padding='same', activation='relu'))

  for i in range(num_layers-1):
    conv_layers.append(tf.keras.layers.Conv2D(64, kernel_size = 3, padding ='same',activation = 'relu'))
    deconv_layers.append(tf.keras.layers.Conv2DTranspose(64, kernel_size = 3, padding = 'same',activation='relu'))
    deconv_layers.append(tf.keras.layers.Conv2DTranspose(3, kernel_size = 3, padding='same', activation='softmax'))
  x = conv_layers[0](inputs)

  #인코더 시작
  for i in range(num_layers-1):
    x = conv_layers[i+1](x)
    if i % 2 == 0:
      residual_layers.append(x)

  #디코더 시작
  for i in range(num_layers-1):
    if i % 2 == 1:
      x = tf.keras.layers.Add()([x, residual_layers.pop()])
      x = tf.keras.layers.Activation('relu')(x)
    x = deconv_layers[i](x) 

  x = deconv_layers[-1](x)
  
  model = tf.keras.Model(inputs=inputs, outputs=x)#inputs과 output이 뭔지 설정하기
  return model 

model = REDNet_segmentation(15)#Segmetiation을 위한 REDNet 네트워크 초기화
model.compile(optimizer = tf.optimizers.Adam(0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])#최적화함수와 손실함수 그리고 나중에 확인할 metrics까지 설정
model.summary()#네트워크망 확인
  
#학습하기 Epochs(학습량) = 20 
history = model.fit(train_dataset, 
                    epochs = 20, 
                    steps_per_epoch= train_data_len//16,
                    validation_data = test_dataset,
                    validation_steps = test_data_len)
                   
#분류한거 눈으로 확인하기                                   
plt.figure(figsize=(12, 12))
for idx, (img, mask) in enumerate(test_dataset.take(3)):
    plt.subplot(3, 3, idx*3+1)
    plt.imshow(img[0])
    
    plt.subplot(3, 3, idx*3+2)
    plt.imshow(np.squeeze(mask[0], axis=2))
    
    predict = tf.argmax(model.predict(img), axis=-1)
    plt.subplot(3, 3, idx*3+3)
    # plt.imshow(np.squeeze(predict[0], axis=0))
    plt.imshow(np.squeeze(predict, axis=0))
    
#테스트 이미지 분할 확인(원본)
plt.figure(figsize=(12, 12))
for idx, datapoint in enumerate(dataset['test'].take(3)):
    img = datapoint['image']
    mask = datapoint['segmentation_mask']
    
    img = tf.cast(img, tf.float32)
    img = img / 255.0
    mask -= 1
    
    plt.subplot(3, 3, idx*3+1)
    plt.imshow(img)
    
    plt.subplot(3, 3, idx*3+2)
    plt.imshow(np.squeeze(mask, axis=2))
    
    predict = tf.argmax(model.predict(tf.expand_dims(img, axis=0)), axis=-1)
    plt.subplot(3, 3, idx*3+3)
    # plt.imshow(np.squeeze(predict[0], axis=0))
    plt.imshow(np.squeeze(predict, axis=0))
  
